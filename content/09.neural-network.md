# Neural Network Analysis

This section explains the output of the neural network model created for this project. For the neural network model development, tensorflow, Sequential from tensorflow.keras.models, Dense from tensorflow.keras.layers, and Adam from tensorflow.keras.optimizers were employed.
The MSE returned from running the model was $7.919958*(1/10^5)$. This MSE value is suspiciously low, and, just as in the previous section "Decision Tree Analysis", the graphs created from the model analysis also indicate a near-perfect correlation between the model and the actual values. These findings once again point towards the possibility of the data being artificially designed, leading to very low variability.
Below is a graph showing the correlation between the training and testing data.

<p align="center">
  <img src="images/training_validation_plot2.png" alt="Training vs validation plot" width="600px">
  <br>
  <strong>Figure 17:</strong> Training vs validation plot
</p>

It is clear to see that the training loss almost perfectly mirrors the validation loss. The following graphs also provide evidence for the possibility that the data was fabricated rather than collected in the real world. Below, in Figure 18, we see how, except for just two data points, all predicted values lie almost perfectly  along the line representing the actual values.

<p align="center">
  <img src="images/predicted_vs_actual2.png" alt="Predicted vs actual values plot" width="600px">
  <br>
  <strong>Figure 18:</strong> Predicted vs actual values plot
</p>

Lastly, as with Figure 18, Figure 19 shows just two outliers while the rest of the data points lie on the line representing the 0 residual value. Residuals are the output of the subtraction between predicted and actual values, and they show how far the predicted values are from the actual ones. The fact that almost all the points are so close to 0 would indicate that there is almost no error between predicted and actual values. This outcome is very unlikely to happen in data with a normal amout of variability, which once again points to the conclusion that the data may have been artificially created.

<p align="center">
  <img src="images/residual_neural_network2.png" alt="Residual plot" width="600px">
  <br>
  <strong>Figure 19:</strong> Residual plot
</p>
